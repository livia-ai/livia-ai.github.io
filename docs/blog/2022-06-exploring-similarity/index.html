<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="description" content="" />
		<link rel="icon" href="../favicon.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- Twitter card metadata -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:image" content="https://livia-ai.github.io/social-preview.png" />
    <!-- OG metadata -->
    <meta property="og:type" content="website" />
    <meta property="og:image" content="https://livia-ai.github.io/social-preview.png" />
    <meta property="og:image:width" content="1000" />
    <meta property="og:image:height" content="500" />
    <meta property="og:url" content="https://livia-ai.github.io/" />
		<meta http-equiv="content-security-policy" content=""><title>LiviaAI | Exploring Similarity: Triplets and How to Choose Them</title><script data-svelte="svelte-11hqmoo">if(!sessionStorage.getItem("_swa")&&document.referrer.indexOf(location.protocol+"//"+location.host)!== 0){fetch("https://counter.dev/track?"+new URLSearchParams({referrer:document.referrer,screen:screen.width+"x"+screen.height,user:"rainer@no5.at",utcoffset:"1"}))};sessionStorage.setItem("_swa","1");</script><script data-svelte="svelte-11hqmoo">if(!sessionStorage.getItem("_swa")&&document.referrer.indexOf(location.protocol+"//"+location.host)!== 0){fetch("https://counter.dev/track?"+new URLSearchParams({referrer:document.referrer,screen:screen.width+"x"+screen.height,user:"rainer@no5.at",utcoffset:"1"}))};sessionStorage.setItem("_swa","1");</script><meta name="description" content="Help us understand the quality of our data by participating in a small crowdsourcing experiment." data-svelte="svelte-4med8m"><meta name="twitter:title" content="Exploring Similarity: Triplets and How to Choose Them" data-svelte="svelte-4med8m"><meta name="twitter:description" content="Help us understand the quality of our data by participating in a small crowdsourcing experiment." data-svelte="svelte-4med8m"><meta property="og:title" content="Exploring Similarity: Triplets and How to Choose Them" data-svelte="svelte-4med8m"><meta property="og:description" content="Help us understand the quality of our data by participating in a small crowdsourcing experiment." data-svelte="svelte-4med8m"><meta property="og:url" content="https://liviaai.at/blog/2022-06-exploring-similarity" data-svelte="svelte-4med8m">
	<link rel="stylesheet" href="/_app/assets/vendor-86f8c920.css">
	<link rel="stylesheet" href="/_app/assets/app-b4fe6dc6.css">
	<link rel="stylesheet" href="/_app/assets/pages/blog/__layout.svelte-27041123.css">
	<link rel="modulepreload" href="/_app/start-1fa4e38b.js">
	<link rel="modulepreload" href="/_app/chunks/vendor-f435face.js">
	<link rel="modulepreload" href="/_app/pages/__layout.svelte-c65b2343.js">
	<link rel="modulepreload" href="/_app/pages/blog/__layout.svelte-1a889f9f.js">
	<link rel="modulepreload" href="/_app/pages/blog/2022-06-exploring-similarity.md-0d27572b.js">
	<link rel="modulepreload" href="/_app/chunks/_post-4f5578a2.js"><script type="module">
		import { start } from "/_app/start-1fa4e38b.js";
		start({
			target: document.querySelector("body"),
			paths: {"base":"","assets":""},
			session: {},
			route: true,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/_app/pages/__layout.svelte-c65b2343.js"),
						import("/_app/pages/blog/__layout.svelte-1a889f9f.js"),
						import("/_app/pages/blog/2022-06-exploring-similarity.md-0d27572b.js")
				],
				url: new URL("http://sveltekit-prerender/blog/2022-06-exploring-similarity"),
				params: {}
			}
		});
	</script>
	</head>
	<body class="leading-relaxed tracking-normal text-white gradient" style="font-family: 'Source Sans Pro', sans-serif;">		
		






<nav id="header" class="fixed w-full z-30 top-0 text-white shadow bg-white"><div class="w-full container mx-auto flex flex-wrap items-center justify-between mt-0 py-2"><div class="pl-4 flex items-center"><a class="text-gray-800 no-underline hover:no-underline font-bold text-2xl lg:text-4xl" href="/">LiviaAI
      </a></div>

    <div class="block lg:hidden pr-4"><button id="nav-toggle" class="flex items-center p-1 text-gray-900 hover:text-gray-900 focus:outline-none focus:shadow-outline transform transition hover:scale-105 duration-300 ease-in-out"><svg class="fill-current h-6 w-6" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><title>Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"></path></svg></button></div>
    <div class="w-full flex-grow lg:flex lg:items-center lg:w-auto hidden mt-2 lg:mt-0 bg-white lg:bg-transparent text-black p-4 lg:p-0 z-20" id="nav-content"><ul class="list-reset lg:flex justify-end flex-1 items-center"><li class="mr-3"><a class="inline-block text-black no-underline hover:text-gray-800 hover:text-underline py-2 px-4" href="/blog/2022-05-community-data">Blog</a></li></ul>
      <button id="navAction" class="mx-auto lg:mx-0 hover:underline gradient font-bold lg:rounded-full mt-4 lg:mt-0 py-4 px-4 lg:px-8 lg:shadow opacity-75 focus:outline-none focus:shadow-outline transform transition hover:scale-105 duration-300 ease-in-out"><a href="/" class="text-white">Home</a></button></div></div>
  <hr class="border-b border-gray-100 opacity-25 my-0 py-0"></nav>

<section class="bg-white py-8"><div class="container max-w-5xl mx-auto m-8 blogpost svelte-1rn5i04"><div class="w-6/6 sm:w-2/2 p-6 text-gray-600">

<h1>Exploring Similarity: Triplets and How to Choose Them</h1>
<h2 class="published-at"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="svelte-c8tyih"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"></path></svg> June 15, 2022</h2>

<p>Following <a href="/blog/2022-05-community-data">our partner workshop in May</a>, we started to re-assess our
technical processes based on the feedback we received. Two take-away points from the workshop
were:</p>
<ol><li><p>When measuring similarity of metadata records, we should focus only on the metadata fields that concern
<strong>subject</strong> and <strong>theme</strong>. This lead us to exclude some fields from our Sentence Embedding workflow (read about
it <a href="/blog/2022-04-machines-reading-metadata">in our earlier blogpost here</a>), in particular those related to
style, collection, and artist.</p></li>
<li><p>We should consider measuring similarity based <strong>exclusively</strong> on the curator-assigned subject tags, even if
other free-text fields (specifically, title and description) exist. This lead us to experiment with an alternative
machine learning technology referred to as <a href="https://towardsdatascience.com/overview-of-deep-learning-on-graph-embeddings-4305c10ad4a4" rel="nofollow">Graph Embedding</a>.</p></li></ol>
<p>Another important outcome from our first experiments - which the workshop confirmed - was that the similarity scores we
had computed did not work well <strong>when combining data from multiple museums</strong>. As the image below illustrates, each museum’s records remain fairly separated from each other. This may be because vocabularies and curating practices differ too much; or, simply, because the collections are inherently too different in terms of their content.</p>
<div style="display:flex; justify-content:center; padding-top:30px;"><img src="/blog/2022-06-exploring-similarity/3d_sentence_embeddings_all.png" alt="3D scatterplot of metadata sentence embedding vectors for all museums combined"></div>
<div style="width:100%" class="image-caption centered">Sentence embeddings vectors for metadata from all museums combined: MAK (blue), Wien Museum (red), Belvedere (green).</div>
<p>This outcome doesn’t exactly make our lives easier - after all, connecting collections is <a href="/blog/2022-04-hello-world">one of LiviaAI’s three main
goals</a>. But it isn’t entirely unexpected either. In fact, we had expected that metadata alone
would be insufficent to connect across collections. Which is why we proposed this project in the first place!</p>
<h2>Triplets</h2>
<p>The goal of LiviaAI is to teach computers how to recognize similar <em>images</em>, rather than similar <em>metadata</em>. To do this, we need to provide examples: the AI needs to see (lots of!) pairs of images that are <strong>similar</strong> to each other, but also images that are <strong>different</strong>.</p>
<p>It is important to understand that the method we use to select those examples is based on the metadata. Similar metadata means we’ll show the images to the AI as examples of similar images. Therefore, in a sense, there’s bit of circular dependency here. But ultimately, the goal is that the AI will figure out what similarity <strong>looks like</strong>, without depending on the metadata any more.</p>
<p>In AI terminology, a group of three images, where the first two are an example of similar images, and the third one is an example of a different image, is called a <strong>triplet</strong>. Good triplets will produce an AI model that can measure similarity in a useful way, thus allowing us to identify related images between collections, regardless of the way their metadata is being recorded in different institutions. To summarize our workflow:</p>
<ul><li>First, we compile lots of triplets, i.e. examples of images that are <strong>similar</strong>, and images that are <strong>different</strong> in terms of theme and subject.</li>
<li>We feed the triplets into the AI, so it learns to “understand” what similarity looks like in the images.</li>
<li>In order to get our examples, we rely on the metadata: because similar subject and themes are described in similar terms <strong>within one museum collection</strong>, records with high metadata similarity should provide us with good image training material.</li></ul>
<h2>Comparing Approaches</h2>
<p>So far, we’ve built triplets for two different museums (the Belvedere and the Wien Museum), and - as written above - using two different methods: Sentence Embeddings and Graph Embeddings. As a next step, we want to understand more about the real-world applicability of these two approaches.</p>
<p>Both approaches present us with a quantitative measure of similarity that’s… technically… accurate: metadata records that include many identical terms, keywords and wording (perhaps with the odd synonym thrown in) <em>will</em> be reliably identified as similar. But the real world isn’t that simple, of course. Metadata isn’t always rich enough to provide enough material for the algorithm (or even humans!) to judge whether two images are similar enough in terms of subject and themes; and curation may not always be consistent, even within the same institution and collection.</p>
<p><strong>That’s why we need your help:</strong> Below, you see a random triplet. Based on the metdata, our algorithm has selected images A and B as similar; and image C as different. Does the choice make sense? You can vote using the two buttons below. </p>
<p>Give us a thumbs-up if images A and B show similar motives or themes, and image C is different from A and B. Give us a thumbs-down if there is little similarity between A and B, or C is too similar to A or B.</p>
<p><strong>We know that ratings are subjective. That’s no problem!</strong> We want to collect as much &amp; as diverse feedback
as possible. If you feel unsure about the process, we recommend:</p>
<ul><li>Don’t overthink it.</li>
<li>Focus on image motives and themes, ignore the medium (e.g. painting, sculpture,…)</li>
<li>Trust your instincts and rate according to your first impression.</li>
<li>If a triple is confusing, this is likely due to ambiguous keywords. Simply skip the triplet.</li></ul>
<iframe src="https://rate-this-triplet.no5.at/embed.html" style="width:100%; height:700px; margin:0"></iframe>
<p>After your vote, a new random triplet will load. Keep going as long as you want - the more data we collect, the better. You can also skip a triplet by clicking the “Skip this Triplet” link. Please do this only in cases where you really (really!) cannot decide, or if there’s a problem loading a particular triplet. When in doubt, your gut feeling helps us more than no vote at all.</p>
<h2>What Happens with the Data?</h2>
<p>First of all: the data we collect is, of course, completely anonymous. All we record is your “Good” or “Bad” rating on each triplet. The data we collect will help us, most importantly, to understand whether there is any significant difference between triplets selected using Sentence Embeddings or Graph Embeddings. It will also help us get a better feel for which museum collection “works better”, as it were, with the two methods.</p>
<p>If we collect enough feedback (and that’s a big if!), we will also be able to train the AI <strong>only</strong> (or, at least, mainly) with triplets that have been confirmed by a human, which will significantly improve the quality of the model.</p>
<p><strong>You can also access the rating app without the blog post here: <a href="https://rate-this-triplet.no5.at" rel="nofollow">https://rate-this-triplet.no5.at</a></strong></p>
<footer><div class="previous-post"><h4>Previous post</h4> 
    <a href="/blog/2022-05-community-data/">Community and Data</a></div></footer></div></div></section>

<svg class="wave-top" viewBox="0 0 1439 147" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g transform="translate(-1.000000, -14.000000)" fill-rule="nonzero"><g class="wave" fill="#fff"><path d="M1440,84 C1383.555,64.3 1342.555,51.3 1317,45 C1259.5,30.824 1206.707,25.526 1169,22 C1129.711,18.326 1044.426,18.475 980,22 C954.25,23.409 922.25,26.742 884,32 C845.122,37.787 818.455,42.121 804,45 C776.833,50.41 728.136,61.77 713,65 C660.023,76.309 621.544,87.729 584,94 C517.525,105.104 484.525,106.438 429,108 C379.49,106.484 342.823,104.484 319,102 C278.571,97.783 231.737,88.736 205,84 C154.629,75.076 86.296,57.743 0,32 L0,0 L1440,0 L1440,84 Z"></path></g><g transform="translate(1.000000, 15.000000)" fill="#FFFFFF"><g transform="translate(719.500000, 68.500000) rotate(-180.000000) translate(-719.500000, -68.500000) "><path d="M0,0 C90.7283404,0.927527913 147.912752,27.187927 291.910178,59.9119003 C387.908462,81.7278826 543.605069,89.334785 759,82.7326078 C469.336065,156.254352 216.336065,153.6679 0,74.9732496" opacity="0.100000001"></path><path d="M100,104.708498 C277.413333,72.2345949 426.147877,52.5246657 546.203633,45.5787101 C666.259389,38.6327546 810.524845,41.7979068 979,55.0741668 C931.069965,56.122511 810.303266,74.8455141 616.699903,111.243176 C423.096539,147.640838 250.863238,145.462612 100,104.708498 Z" opacity="0.100000001"></path><path d="M1046,51.6521276 C1130.83045,29.328812 1279.08318,17.607883 1439,40.1656806 L1439,120 C1271.17211,77.9435312 1140.17211,55.1609071 1046,51.6521276 Z" opacity="0.200000003"></path></g></g></g></g></svg>

<footer class="gradient"><div class="container mx-auto px-8 pb-6"><div class="w-full flex flex-col md:flex-row py-6"><div class="flex-1"><ul class="list-reset mb-6"><li class="mt-2 inline-block mr-2 md:block md:mr-0">Funded by<br>
            <a href="https://www.oeaw.ac.at/foerderungen/jubilaeumsfonds/1/ausschreibung-2017/1/jubilaeumsfonds-gefoerderte-projekte-2017-1" class="text-white">Jubiläumsfonds der Stadt Wien für die ÖAW
            </a></li></ul></div></div></div>
</footer>


	</body>
</html>
