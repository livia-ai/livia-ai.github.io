import{S as Mi,i as qi,s as Fi,C as qa,w as Hi,x as $i,y as zi,z as Ki,A as Ni,q as Yi,o as Vi,B as Ui,Q as Wi,e as s,t as i,k as m,c as r,a as l,h as o,d as a,m as d,b as c,O as Li,f as M,g as h,H as t}from"../../chunks/vendor-f435face.js";import{P as Ji}from"../../chunks/_post-4f5578a2.js";function Qi(K){let u,A,p,q,f,w,E,me,k,ct,de,pt,wt,ue,gt,yt,Y,vt,bt,_t,fe,I,Et,ce,kt,At,F,It,Tt,Le,G,xt,pe,Gt,St,Ce,T,V,Fa,De,S,Bt,Me,B,jt,U,Ot,Rt,qe,g,Pt,we,Nt,Wt,ge,Lt,Ct,ye,Dt,Mt,Fe,J,qt,He,j,Ft,ve,Ht,$t,$e,O,x,zt,be,Kt,Yt,_e,Vt,Ut,Jt,Ee,Qt,ze,y,Xt,ke,Zt,ea,Ae,ta,aa,Ie,ia,oa,Ke,Q,sa,Ye,X,ra,Ve,Z,la,Ue,H,Te,na,ha,Je,ee,ma,Qe,v,da,xe,ua,fa,Ge,ca,pa,Se,wa,ga,Xe,$,Be,ya,va,Ze,b,je,ba,_a,Oe,Ea,ka,Re,Aa,Ia,Pe,Ta,et,_,Ha,tt,te,xa,at,ae,Ga,it,ie,Sa,ot,R,Ba,Ne,ja,Oa,st,oe,se,Ra,z,Pa,rt,re,P,We,Na,Wa,le,La;return{c(){u=s("p"),A=i("Following "),p=s("a"),q=i("our partner workshop in May"),f=i(`, we started to re-assess our
technical processes based on the feedback we received. Two take-away points from the workshop
were:`),w=m(),E=s("ol"),me=s("li"),k=s("p"),ct=i(`When measuring similarity of metadata records, we should focus only on the metadata fields that concern
`),de=s("strong"),pt=i("subject"),wt=i(" and "),ue=s("strong"),gt=i("theme"),yt=i(`. This lead us to exclude some fields from our Sentence Embedding workflow (read about
it `),Y=s("a"),vt=i("in our earlier blogpost here"),bt=i(`), in particular those related to
style, collection, and artist.`),_t=m(),fe=s("li"),I=s("p"),Et=i("We should consider measuring similarity based "),ce=s("strong"),kt=i("exclusively"),At=i(` on the curator-assigned subject tags, even if
other free-text fields (specifically, title and description) exist. This lead us to experiment with an alternative
machine learning technology referred to as `),F=s("a"),It=i("Graph Embedding"),Tt=i("."),Le=m(),G=s("p"),xt=i(`Another important outcome from our first experiments - which the workshop confirmed - was that the similarity scores we
had computed did not work well `),pe=s("strong"),Gt=i("when combining data from multiple museums"),St=i(". As the image below illustrates, each museum\u2019s records remain fairly separated from each other. This may be because vocabularies and curating practices differ too much; or, simply, because the collections are inherently too different in terms of their content."),Ce=m(),T=s("div"),V=s("img"),De=m(),S=s("div"),Bt=i("Sentence embeddings vectors for metadata from all museums combined: MAK (blue), Wien Museum (red), Belvedere (green)."),Me=m(),B=s("p"),jt=i("This outcome doesn\u2019t exactly make our lives easier - after all, connecting collections is "),U=s("a"),Ot=i(`one of LiviaAI\u2019s three main
goals`),Rt=i(`. But it isn\u2019t entirely unexpected either. In fact, we had expected that metadata alone
would be insufficent to connect across collections. Which is why we proposed this project in the first place!`),qe=m(),g=s("p"),Pt=i("The goal of LiviaAI is to teach computers how to recognize similar "),we=s("strong"),Nt=i("images"),Wt=i(", rather than similar "),ge=s("strong"),Lt=i("metadata"),Ct=i(". To do this, we need to provide examples: the AI needs to see (lots of!) pairs of images that are similar to each other, but also images that are different, so that it learns what similarity looks like, "),ye=s("strong"),Dt=i("without depending on the metadata"),Mt=i("."),Fe=m(),J=s("h2"),qt=i("Triplets"),He=m(),j=s("p"),Ft=i("In AI terminology, a group of three images, where the first two are examples of similar images, and the third one is an example of a different image, is called a "),ve=s("strong"),Ht=i("triplet"),$t=i(". Good triplets will produce an AI model that can measure similarity in a useful way, allowing us to identify related images, no matter which collection they come from. To summarize our workflow:"),$e=m(),O=s("ul"),x=s("li"),zt=i("First, we compile lots of triplets, i.e. examples of images that are "),be=s("strong"),Kt=i("similar"),Yt=i(", and images that are "),_e=s("strong"),Vt=i("different"),Ut=i(" in terms of theme and subject."),Jt=m(),Ee=s("li"),Qt=i("We feed the triplets into the AI, so it learns to \u201Cunderstand\u201D what similarity looks like."),ze=m(),y=s("p"),Xt=i("It is important to understand that the method we use to "),ke=s("strong"),Zt=i("select"),ea=i(" our triplets is still based on the metadata: similar metadata means we\u2019ll show it to the AI as an example of similar images; and because similar subject and themes are described in similar terms "),Ae=s("strong"),ta=i("within one museum collection"),aa=i(", this approach is sensible. But ultimately, the AI is supposed to learn the "),Ie=s("strong"),ia=i("visual representation"),oa=i(" of similarity. And that, in turn, means it will have much less problems dealing with mixed content from different collections."),Ke=m(),Q=s("h2"),sa=i("Comparing Approaches"),Ye=m(),X=s("p"),ra=i("So far, we\u2019ve built triplets for two different museums (the Belvedere and the Wien Museum), and - as written above - using two different methods: Sentence Embeddings and Graph Embeddings. As a next step, we want to understand more about the real-world applicability of both approaches."),Ve=m(),Z=s("p"),la=i("Each approach presents us with a quantitative measure of similarity that\u2019s\u2026 technically\u2026 accurate: metadata records that include many identical terms, keywords and wording (perhaps with the odd synonym thrown in) will be reliably identified as similar. But the real world isn\u2019t that simple, of course. Metadata isn\u2019t always rich enough to provide enough material for the algorithm (or even humans!) to judge whether two images are similar enough in terms of subject and themes; and curation may not always be consistent, even within the same institution and collection."),Ue=m(),H=s("p"),Te=s("strong"),na=i("That\u2019s why we need your help:"),ha=i(" Below, you see a random triplet. Based on the metdata, our algorithm has selected images A and B as similar; and image C as different. Does the choice make sense? You can vote using the two buttons below."),Je=m(),ee=s("p"),ma=i("Give us a thumbs-up if images A and B show similar motives or themes, and image C is different from A and B. Give us a thumbs-down if there is little similarity between A and B, or C is too similar to A or B."),Qe=m(),v=s("p"),da=i("Remember: what the computer thinks is a "),xe=s("strong"),ua=i("good"),fa=i(" triplet and what a person might think are a "),Ge=s("strong"),ca=i("good"),pa=i(" triplet may be quite divergent, which is exactly why we need to the human input (ie: your help). A human-made judgement on similarity and difference (whether the person doing the evaluation has professional art historical training or not) will always be valuable. If we manage to get enough ratings, the disagreements will also certainly help us to spot difficult cases. It\u2019s also worth bearing in mind that sometimes it is easier to judge what makes a "),Se=s("strong"),wa=i("bad"),ga=i(" triplet, than what makes a good one. Trust your instincts!"),Xe=m(),$=s("p"),Be=s("strong"),ya=i("We know that ratings are subjective. That\u2019s no problem!"),va=i(` We want to collect as much & as diverse feedback
as possible. If you feel unsure about the process, we recommend:`),Ze=m(),b=s("ul"),je=s("li"),ba=i("Don\u2019t overthink it."),_a=m(),Oe=s("li"),Ea=i("Focus on image motives and themes, ignore the medium (e.g. painting, sculpture,\u2026)"),ka=m(),Re=s("li"),Aa=i("Trust your instincts and rate according to your first impression."),Ia=m(),Pe=s("li"),Ta=i("If a triplet looks confusing, this is likely due to ambiguous keywords. In this case, you can simply skip it."),et=m(),_=s("iframe"),tt=m(),te=s("p"),xa=i("After your vote, a new random triplet will load. Keep going as long as you want - the more data we collect, the better. If you need to skip a triplet, click the \u201CSkip this Triplet\u201D link. But please do this only in cases where you really (really!) cannot decide, or if there\u2019s a problem loading a particular triplet. When in doubt, your gut feeling helps us more than no vote at all."),at=m(),ae=s("h2"),Ga=i("What Happens with the Data?"),it=m(),ie=s("p"),Sa=i("First of all: the data we collect is, of course, completely anonymous. All we record is your \u201CGood\u201D or \u201CBad\u201D rating on each triplet. The data we collect will help us, most importantly, to understand whether there is any significant difference between triplets selected using Sentence Embeddings or Graph Embeddings. It will also help us get a better feel for which museum collection \u201Cworks better\u201D, as it were, with the two methods."),ot=m(),R=s("p"),Ba=i("If we collect enough feedback (and that\u2019s a big if!), we will also be able to train the AI "),Ne=s("strong"),ja=i("only"),Oa=i(" (or, at least, mainly) with triplets that have been confirmed by a human, which will significantly improve the quality of the model."),st=m(),oe=s("p"),se=s("strong"),Ra=i("You can also access the rating app without the blog post here: "),z=s("a"),Pa=i("https://rate-this-triplet.no5.at"),rt=m(),re=s("footer"),P=s("div"),We=s("h4"),Na=i("Previous post"),Wa=m(),le=s("a"),La=i("Community and Data"),this.h()},l(e){u=r(e,"P",{});var n=l(u);A=o(n,"Following "),p=r(n,"A",{href:!0});var $a=l(p);q=o($a,"our partner workshop in May"),$a.forEach(a),f=o(n,`, we started to re-assess our
technical processes based on the feedback we received. Two take-away points from the workshop
were:`),n.forEach(a),w=d(e),E=r(e,"OL",{});var lt=l(E);me=r(lt,"LI",{});var za=l(me);k=r(za,"P",{});var N=l(k);ct=o(N,`When measuring similarity of metadata records, we should focus only on the metadata fields that concern
`),de=r(N,"STRONG",{});var Ka=l(de);pt=o(Ka,"subject"),Ka.forEach(a),wt=o(N," and "),ue=r(N,"STRONG",{});var Ya=l(ue);gt=o(Ya,"theme"),Ya.forEach(a),yt=o(N,`. This lead us to exclude some fields from our Sentence Embedding workflow (read about
it `),Y=r(N,"A",{href:!0});var Va=l(Y);vt=o(Va,"in our earlier blogpost here"),Va.forEach(a),bt=o(N,`), in particular those related to
style, collection, and artist.`),N.forEach(a),za.forEach(a),_t=d(lt),fe=r(lt,"LI",{});var Ua=l(fe);I=r(Ua,"P",{});var ne=l(I);Et=o(ne,"We should consider measuring similarity based "),ce=r(ne,"STRONG",{});var Ja=l(ce);kt=o(Ja,"exclusively"),Ja.forEach(a),At=o(ne,` on the curator-assigned subject tags, even if
other free-text fields (specifically, title and description) exist. This lead us to experiment with an alternative
machine learning technology referred to as `),F=r(ne,"A",{href:!0,rel:!0});var Qa=l(F);It=o(Qa,"Graph Embedding"),Qa.forEach(a),Tt=o(ne,"."),ne.forEach(a),Ua.forEach(a),lt.forEach(a),Le=d(e),G=r(e,"P",{});var nt=l(G);xt=o(nt,`Another important outcome from our first experiments - which the workshop confirmed - was that the similarity scores we
had computed did not work well `),pe=r(nt,"STRONG",{});var Xa=l(pe);Gt=o(Xa,"when combining data from multiple museums"),Xa.forEach(a),St=o(nt,". As the image below illustrates, each museum\u2019s records remain fairly separated from each other. This may be because vocabularies and curating practices differ too much; or, simply, because the collections are inherently too different in terms of their content."),nt.forEach(a),Ce=d(e),T=r(e,"DIV",{style:!0});var Za=l(T);V=r(Za,"IMG",{src:!0,alt:!0}),Za.forEach(a),De=d(e),S=r(e,"DIV",{style:!0,class:!0});var ei=l(S);Bt=o(ei,"Sentence embeddings vectors for metadata from all museums combined: MAK (blue), Wien Museum (red), Belvedere (green)."),ei.forEach(a),Me=d(e),B=r(e,"P",{});var ht=l(B);jt=o(ht,"This outcome doesn\u2019t exactly make our lives easier - after all, connecting collections is "),U=r(ht,"A",{href:!0});var ti=l(U);Ot=o(ti,`one of LiviaAI\u2019s three main
goals`),ti.forEach(a),Rt=o(ht,`. But it isn\u2019t entirely unexpected either. In fact, we had expected that metadata alone
would be insufficent to connect across collections. Which is why we proposed this project in the first place!`),ht.forEach(a),qe=d(e),g=r(e,"P",{});var W=l(g);Pt=o(W,"The goal of LiviaAI is to teach computers how to recognize similar "),we=r(W,"STRONG",{});var ai=l(we);Nt=o(ai,"images"),ai.forEach(a),Wt=o(W,", rather than similar "),ge=r(W,"STRONG",{});var ii=l(ge);Lt=o(ii,"metadata"),ii.forEach(a),Ct=o(W,". To do this, we need to provide examples: the AI needs to see (lots of!) pairs of images that are similar to each other, but also images that are different, so that it learns what similarity looks like, "),ye=r(W,"STRONG",{});var oi=l(ye);Dt=o(oi,"without depending on the metadata"),oi.forEach(a),Mt=o(W,"."),W.forEach(a),Fe=d(e),J=r(e,"H2",{});var si=l(J);qt=o(si,"Triplets"),si.forEach(a),He=d(e),j=r(e,"P",{});var mt=l(j);Ft=o(mt,"In AI terminology, a group of three images, where the first two are examples of similar images, and the third one is an example of a different image, is called a "),ve=r(mt,"STRONG",{});var ri=l(ve);Ht=o(ri,"triplet"),ri.forEach(a),$t=o(mt,". Good triplets will produce an AI model that can measure similarity in a useful way, allowing us to identify related images, no matter which collection they come from. To summarize our workflow:"),mt.forEach(a),$e=d(e),O=r(e,"UL",{});var dt=l(O);x=r(dt,"LI",{});var he=l(x);zt=o(he,"First, we compile lots of triplets, i.e. examples of images that are "),be=r(he,"STRONG",{});var li=l(be);Kt=o(li,"similar"),li.forEach(a),Yt=o(he,", and images that are "),_e=r(he,"STRONG",{});var ni=l(_e);Vt=o(ni,"different"),ni.forEach(a),Ut=o(he," in terms of theme and subject."),he.forEach(a),Jt=d(dt),Ee=r(dt,"LI",{});var hi=l(Ee);Qt=o(hi,"We feed the triplets into the AI, so it learns to \u201Cunderstand\u201D what similarity looks like."),hi.forEach(a),dt.forEach(a),ze=d(e),y=r(e,"P",{});var L=l(y);Xt=o(L,"It is important to understand that the method we use to "),ke=r(L,"STRONG",{});var mi=l(ke);Zt=o(mi,"select"),mi.forEach(a),ea=o(L," our triplets is still based on the metadata: similar metadata means we\u2019ll show it to the AI as an example of similar images; and because similar subject and themes are described in similar terms "),Ae=r(L,"STRONG",{});var di=l(Ae);ta=o(di,"within one museum collection"),di.forEach(a),aa=o(L,", this approach is sensible. But ultimately, the AI is supposed to learn the "),Ie=r(L,"STRONG",{});var ui=l(Ie);ia=o(ui,"visual representation"),ui.forEach(a),oa=o(L," of similarity. And that, in turn, means it will have much less problems dealing with mixed content from different collections."),L.forEach(a),Ke=d(e),Q=r(e,"H2",{});var fi=l(Q);sa=o(fi,"Comparing Approaches"),fi.forEach(a),Ye=d(e),X=r(e,"P",{});var ci=l(X);ra=o(ci,"So far, we\u2019ve built triplets for two different museums (the Belvedere and the Wien Museum), and - as written above - using two different methods: Sentence Embeddings and Graph Embeddings. As a next step, we want to understand more about the real-world applicability of both approaches."),ci.forEach(a),Ve=d(e),Z=r(e,"P",{});var pi=l(Z);la=o(pi,"Each approach presents us with a quantitative measure of similarity that\u2019s\u2026 technically\u2026 accurate: metadata records that include many identical terms, keywords and wording (perhaps with the odd synonym thrown in) will be reliably identified as similar. But the real world isn\u2019t that simple, of course. Metadata isn\u2019t always rich enough to provide enough material for the algorithm (or even humans!) to judge whether two images are similar enough in terms of subject and themes; and curation may not always be consistent, even within the same institution and collection."),pi.forEach(a),Ue=d(e),H=r(e,"P",{});var Ca=l(H);Te=r(Ca,"STRONG",{});var wi=l(Te);na=o(wi,"That\u2019s why we need your help:"),wi.forEach(a),ha=o(Ca," Below, you see a random triplet. Based on the metdata, our algorithm has selected images A and B as similar; and image C as different. Does the choice make sense? You can vote using the two buttons below."),Ca.forEach(a),Je=d(e),ee=r(e,"P",{});var gi=l(ee);ma=o(gi,"Give us a thumbs-up if images A and B show similar motives or themes, and image C is different from A and B. Give us a thumbs-down if there is little similarity between A and B, or C is too similar to A or B."),gi.forEach(a),Qe=d(e),v=r(e,"P",{});var C=l(v);da=o(C,"Remember: what the computer thinks is a "),xe=r(C,"STRONG",{});var yi=l(xe);ua=o(yi,"good"),yi.forEach(a),fa=o(C," triplet and what a person might think are a "),Ge=r(C,"STRONG",{});var vi=l(Ge);ca=o(vi,"good"),vi.forEach(a),pa=o(C," triplet may be quite divergent, which is exactly why we need to the human input (ie: your help). A human-made judgement on similarity and difference (whether the person doing the evaluation has professional art historical training or not) will always be valuable. If we manage to get enough ratings, the disagreements will also certainly help us to spot difficult cases. It\u2019s also worth bearing in mind that sometimes it is easier to judge what makes a "),Se=r(C,"STRONG",{});var bi=l(Se);wa=o(bi,"bad"),bi.forEach(a),ga=o(C," triplet, than what makes a good one. Trust your instincts!"),C.forEach(a),Xe=d(e),$=r(e,"P",{});var Da=l($);Be=r(Da,"STRONG",{});var _i=l(Be);ya=o(_i,"We know that ratings are subjective. That\u2019s no problem!"),_i.forEach(a),va=o(Da,` We want to collect as much & as diverse feedback
as possible. If you feel unsure about the process, we recommend:`),Da.forEach(a),Ze=d(e),b=r(e,"UL",{});var D=l(b);je=r(D,"LI",{});var Ei=l(je);ba=o(Ei,"Don\u2019t overthink it."),Ei.forEach(a),_a=d(D),Oe=r(D,"LI",{});var ki=l(Oe);Ea=o(ki,"Focus on image motives and themes, ignore the medium (e.g. painting, sculpture,\u2026)"),ki.forEach(a),ka=d(D),Re=r(D,"LI",{});var Ai=l(Re);Aa=o(Ai,"Trust your instincts and rate according to your first impression."),Ai.forEach(a),Ia=d(D),Pe=r(D,"LI",{});var Ii=l(Pe);Ta=o(Ii,"If a triplet looks confusing, this is likely due to ambiguous keywords. In this case, you can simply skip it."),Ii.forEach(a),D.forEach(a),et=d(e),_=r(e,"IFRAME",{class:!0,src:!0,style:!0});var Di=l(_);Di.forEach(a),tt=d(e),te=r(e,"P",{});var Ti=l(te);xa=o(Ti,"After your vote, a new random triplet will load. Keep going as long as you want - the more data we collect, the better. If you need to skip a triplet, click the \u201CSkip this Triplet\u201D link. But please do this only in cases where you really (really!) cannot decide, or if there\u2019s a problem loading a particular triplet. When in doubt, your gut feeling helps us more than no vote at all."),Ti.forEach(a),at=d(e),ae=r(e,"H2",{});var xi=l(ae);Ga=o(xi,"What Happens with the Data?"),xi.forEach(a),it=d(e),ie=r(e,"P",{});var Gi=l(ie);Sa=o(Gi,"First of all: the data we collect is, of course, completely anonymous. All we record is your \u201CGood\u201D or \u201CBad\u201D rating on each triplet. The data we collect will help us, most importantly, to understand whether there is any significant difference between triplets selected using Sentence Embeddings or Graph Embeddings. It will also help us get a better feel for which museum collection \u201Cworks better\u201D, as it were, with the two methods."),Gi.forEach(a),ot=d(e),R=r(e,"P",{});var ut=l(R);Ba=o(ut,"If we collect enough feedback (and that\u2019s a big if!), we will also be able to train the AI "),Ne=r(ut,"STRONG",{});var Si=l(Ne);ja=o(Si,"only"),Si.forEach(a),Oa=o(ut," (or, at least, mainly) with triplets that have been confirmed by a human, which will significantly improve the quality of the model."),ut.forEach(a),st=d(e),oe=r(e,"P",{});var Bi=l(oe);se=r(Bi,"STRONG",{});var Ma=l(se);Ra=o(Ma,"You can also access the rating app without the blog post here: "),z=r(Ma,"A",{href:!0,rel:!0});var ji=l(z);Pa=o(ji,"https://rate-this-triplet.no5.at"),ji.forEach(a),Ma.forEach(a),Bi.forEach(a),rt=d(e),re=r(e,"FOOTER",{});var Oi=l(re);P=r(Oi,"DIV",{class:!0});var ft=l(P);We=r(ft,"H4",{});var Ri=l(We);Na=o(Ri,"Previous post"),Ri.forEach(a),Wa=d(ft),le=r(ft,"A",{href:!0});var Pi=l(le);La=o(Pi,"Community and Data"),Pi.forEach(a),ft.forEach(a),Oi.forEach(a),this.h()},h(){c(p,"href","/blog/2022-05-community-data"),c(Y,"href","/blog/2022-04-machines-reading-metadata"),c(F,"href","https://towardsdatascience.com/overview-of-deep-learning-on-graph-embeddings-4305c10ad4a4"),c(F,"rel","nofollow"),Li(V.src,Fa="/blog/2022-06-exploring-similarity/3d_sentence_embeddings_all.png")||c(V,"src",Fa),c(V,"alt","3D scatterplot of metadata sentence embedding vectors for all museums combined"),M(T,"display","flex"),M(T,"justify-content","center"),M(T,"padding-top","30px"),M(S,"width","100%"),c(S,"class","image-caption centered"),c(U,"href","/blog/2022-04-hello-world"),c(_,"class","exploring-similarity-iframe"),Li(_.src,Ha="https://rate-this-triplet.no5.at/embed.html")||c(_,"src",Ha),M(_,"width","100%"),M(_,"height","700px"),M(_,"margin","0"),M(_,"transform","none"),c(z,"href","https://rate-this-triplet.no5.at"),c(z,"rel","nofollow"),c(le,"href","/blog/2022-05-community-data/"),c(P,"class","previous-post")},m(e,n){h(e,u,n),t(u,A),t(u,p),t(p,q),t(u,f),h(e,w,n),h(e,E,n),t(E,me),t(me,k),t(k,ct),t(k,de),t(de,pt),t(k,wt),t(k,ue),t(ue,gt),t(k,yt),t(k,Y),t(Y,vt),t(k,bt),t(E,_t),t(E,fe),t(fe,I),t(I,Et),t(I,ce),t(ce,kt),t(I,At),t(I,F),t(F,It),t(I,Tt),h(e,Le,n),h(e,G,n),t(G,xt),t(G,pe),t(pe,Gt),t(G,St),h(e,Ce,n),h(e,T,n),t(T,V),h(e,De,n),h(e,S,n),t(S,Bt),h(e,Me,n),h(e,B,n),t(B,jt),t(B,U),t(U,Ot),t(B,Rt),h(e,qe,n),h(e,g,n),t(g,Pt),t(g,we),t(we,Nt),t(g,Wt),t(g,ge),t(ge,Lt),t(g,Ct),t(g,ye),t(ye,Dt),t(g,Mt),h(e,Fe,n),h(e,J,n),t(J,qt),h(e,He,n),h(e,j,n),t(j,Ft),t(j,ve),t(ve,Ht),t(j,$t),h(e,$e,n),h(e,O,n),t(O,x),t(x,zt),t(x,be),t(be,Kt),t(x,Yt),t(x,_e),t(_e,Vt),t(x,Ut),t(O,Jt),t(O,Ee),t(Ee,Qt),h(e,ze,n),h(e,y,n),t(y,Xt),t(y,ke),t(ke,Zt),t(y,ea),t(y,Ae),t(Ae,ta),t(y,aa),t(y,Ie),t(Ie,ia),t(y,oa),h(e,Ke,n),h(e,Q,n),t(Q,sa),h(e,Ye,n),h(e,X,n),t(X,ra),h(e,Ve,n),h(e,Z,n),t(Z,la),h(e,Ue,n),h(e,H,n),t(H,Te),t(Te,na),t(H,ha),h(e,Je,n),h(e,ee,n),t(ee,ma),h(e,Qe,n),h(e,v,n),t(v,da),t(v,xe),t(xe,ua),t(v,fa),t(v,Ge),t(Ge,ca),t(v,pa),t(v,Se),t(Se,wa),t(v,ga),h(e,Xe,n),h(e,$,n),t($,Be),t(Be,ya),t($,va),h(e,Ze,n),h(e,b,n),t(b,je),t(je,ba),t(b,_a),t(b,Oe),t(Oe,Ea),t(b,ka),t(b,Re),t(Re,Aa),t(b,Ia),t(b,Pe),t(Pe,Ta),h(e,et,n),h(e,_,n),h(e,tt,n),h(e,te,n),t(te,xa),h(e,at,n),h(e,ae,n),t(ae,Ga),h(e,it,n),h(e,ie,n),t(ie,Sa),h(e,ot,n),h(e,R,n),t(R,Ba),t(R,Ne),t(Ne,ja),t(R,Oa),h(e,st,n),h(e,oe,n),t(oe,se),t(se,Ra),t(se,z),t(z,Pa),h(e,rt,n),h(e,re,n),t(re,P),t(P,We),t(We,Na),t(P,Wa),t(P,le),t(le,La)},d(e){e&&a(u),e&&a(w),e&&a(E),e&&a(Le),e&&a(G),e&&a(Ce),e&&a(T),e&&a(De),e&&a(S),e&&a(Me),e&&a(B),e&&a(qe),e&&a(g),e&&a(Fe),e&&a(J),e&&a(He),e&&a(j),e&&a($e),e&&a(O),e&&a(ze),e&&a(y),e&&a(Ke),e&&a(Q),e&&a(Ye),e&&a(X),e&&a(Ve),e&&a(Z),e&&a(Ue),e&&a(H),e&&a(Je),e&&a(ee),e&&a(Qe),e&&a(v),e&&a(Xe),e&&a($),e&&a(Ze),e&&a(b),e&&a(et),e&&a(_),e&&a(tt),e&&a(te),e&&a(at),e&&a(ae),e&&a(it),e&&a(ie),e&&a(ot),e&&a(R),e&&a(st),e&&a(oe),e&&a(rt),e&&a(re)}}}function Xi(K){let u,A;const p=[K[0],Ci];let q={$$slots:{default:[Qi]},$$scope:{ctx:K}};for(let f=0;f<p.length;f+=1)q=qa(q,p[f]);return u=new Ji({props:q}),{c(){Hi(u.$$.fragment)},l(f){$i(u.$$.fragment,f)},m(f,w){zi(u,f,w),A=!0},p(f,[w]){const E=w&1?Ki(p,[w&1&&Ni(f[0]),w&0&&Ni(Ci)]):{};w&2&&(E.$$scope={dirty:w,ctx:f}),u.$set(E)},i(f){A||(Yi(u.$$.fragment,f),A=!0)},o(f){Vi(u.$$.fragment,f),A=!1},d(f){Ui(u,f)}}}const Ci={title:"Exploring Similarity: Triplets and How to Choose Them",description:"Help us understand the quality of our data by participating in a small crowdsourcing experiment.",url:"https://liviaai.at/blog/2022-06-exploring-similarity",date:"June 15, 2022"};function Zi(K,u,A){return K.$$set=p=>{A(0,u=qa(qa({},u),Wi(p)))},u=Wi(u),[u]}class ao extends Mi{constructor(u){super();qi(this,u,Zi,Xi,Fi,{})}}export{ao as default,Ci as metadata};
